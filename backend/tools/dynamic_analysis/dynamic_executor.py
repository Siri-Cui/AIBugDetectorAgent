# -*- coding: utf-8 -*-
"""
åŠ¨æ€æ‰§è¡Œå™¨(å®Œå…¨é‡æ„ç‰ˆ - ä¿®å¤äº¤å‰æ±¡æŸ“)
æ ¸å¿ƒæ”¹åŠ¨:
1. æŒ‰åç¼€åˆ†ç»„å¯æ‰§è¡Œæ–‡ä»¶
2. æ¯ä¸ªå·¥å…·åªæ‰§è¡Œå¯¹åº”åç¼€çš„æ–‡ä»¶
3. **æ·»åŠ å»é‡é€»è¾‘,é˜²æ­¢é‡å¤é—®é¢˜**
"""
import re  # æ–°å¢ï¼šç”¨äºé²æ£’è§£æè¡Œå·
import os
import asyncio
import subprocess
from typing import Dict, List, Any, Set, Tuple, Tuple, Optional 
import hashlib

from .valgrind_wrapper import ValgrindWrapper
from .sanitizer_wrapper import SanitizerWrapper
from utils.logger import log_info, log_error, log_warning
from backend.agents.ai_postprocessor import get_ai_postprocessor


class DynamicExecutor:
    """åŠ¨æ€åˆ†ææ‰§è¡Œå™¨"""

    def __init__(self):
        self.valgrind = ValgrindWrapper()
        self.sanitizer = SanitizerWrapper()
        self.default_timeout = 300

    async def execute_dynamic_analysis(
        self,
        project_path: str,
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„åŠ¨æ€åˆ†ææµç¨‹"""
        try:
            log_info("å¼€å§‹åŠ¨æ€åˆ†æ")

            # æå–é…ç½®
            tools: List[str] = config.get('tools', ['valgrind_memcheck'])
            executable_args: List[str] = config.get('executable_args', [])
            timeout: int = config.get('timeout', self.default_timeout)
            output_dir: str = config.get('output_dir', '/tmp/dynamic_analysis')

            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)




            # ===== æ­¥éª¤1: è·å–å¯æ‰§è¡Œæ–‡ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„æ˜ å°„ï¼‰=====
            executables_map_param = config.get('executables_map')

            if executables_map_param:
                # ğŸ”¥ ä½¿ç”¨ä¼ å…¥çš„æ˜ å°„ï¼ˆæ¥è‡ª workflowï¼‰
                log_info(f"âœ… ä½¿ç”¨ä¼ å…¥çš„å¯æ‰§è¡Œæ–‡ä»¶æ˜ å°„ï¼ˆ{len(executables_map_param)} ä¸ªå·¥å…·ï¼‰")
                
                all_executables = []
                for tool_name, exe_list in executables_map_param.items():
                    for exe in exe_list:
                        if os.path.exists(exe) and os.path.isfile(exe):
                            all_executables.append(exe)
                            log_info(f"   ğŸ“ {tool_name}: {exe}")
                        else:
                            log_warning(f"   âš ï¸  {tool_name} çš„æ–‡ä»¶ä¸å­˜åœ¨: {exe}")
                
                if not all_executables:
                    return {
                        'success': False,
                        'error': 'ä¼ å…¥çš„å¯æ‰§è¡Œæ–‡ä»¶æ˜ å°„ä¸ºç©ºæˆ–æ–‡ä»¶å‡ä¸å­˜åœ¨'
                    }
                
                log_info(f"âœ… å…± {len(all_executables)} ä¸ªæœ‰æ•ˆå¯æ‰§è¡Œæ–‡ä»¶")
            if executables_map_param:
                log_info(f"âœ… ä½¿ç”¨ä¼ å…¥çš„å¯æ‰§è¡Œæ–‡ä»¶æ˜ å°„ï¼ˆ{len(executables_map_param)} ä¸ªå·¥å…·ï¼‰")
                    
                all_executables = []
                failed_count = 0
                for tool_name, exe_list in executables_map_param.items():
                    for exe in exe_list:
                        if os.path.exists(exe) and os.path.isfile(exe):
                            all_executables.append(exe)
                            log_info(f"   ğŸ“ {tool_name}: {exe}")
                        else:
                            failed_count += 1
                            log_warning(f"   âš ï¸  {tool_name} çš„æ–‡ä»¶ä¸å­˜åœ¨: {exe}")
                    
                    # ===== ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šåªæœ‰åœ¨å®Œå…¨æ²¡æœ‰å¯æ‰§è¡Œæ–‡ä»¶æ—¶æ‰å¤±è´¥ =====
                if not all_executables:
                    log_error(f"âŒ æ‰€æœ‰å¯æ‰§è¡Œæ–‡ä»¶å‡ä¸å­˜åœ¨ï¼ˆå¤±è´¥ {failed_count} ä¸ªï¼‰")
                    return {
                        'success': False,
                        'error': 'ä¼ å…¥çš„å¯æ‰§è¡Œæ–‡ä»¶æ˜ å°„ä¸ºç©ºæˆ–æ–‡ä»¶å‡ä¸å­˜åœ¨',
                        'issues': [],  # â† è¿”å›ç©ºé—®é¢˜åˆ—è¡¨è€Œä¸æ˜¯å®Œå…¨å¤±è´¥
                        'summary': {
                            'total_issues': 0,
                            'tools_run': 0,
                            'compilation_failed': True
                        }
                    }
                    
                    # ===== éƒ¨åˆ†æˆåŠŸç»§ç»­æ‰§è¡Œ =====
                log_info(f"âœ… å…± {len(all_executables)} ä¸ªæœ‰æ•ˆå¯æ‰§è¡Œæ–‡ä»¶ï¼ˆå¤±è´¥ {failed_count} ä¸ªï¼‰")


            # ===== æ­¥éª¤2: æŒ‰åç¼€åˆ†ç»„å¯æ‰§è¡Œæ–‡ä»¶ =====
            executables_by_tool = self._group_executables_by_suffix(all_executables)
            
            log_info("ğŸ“¦ æŒ‰å·¥å…·åˆ†ç»„çš„å¯æ‰§è¡Œæ–‡ä»¶:")
            for tool, execs in executables_by_tool.items():
                if execs:
                    log_info(f"   {tool}: {len(execs)} ä¸ªæ–‡ä»¶")
                    for exe in execs[:3]:
                        log_info(f"      - {os.path.basename(exe)}")
                    if len(execs) > 3:
                        log_info(f"      ... è¿˜æœ‰ {len(execs)-3} ä¸ªæ–‡ä»¶")

            # ===== æ­¥éª¤3: çº¿ç¨‹æ£€æµ‹ =====
            has_threads = self._detect_threading(project_path)
            if has_threads:
                log_info("âœ… æ£€æµ‹åˆ°å¤šçº¿ç¨‹ä»£ç ")
                if 'tsan' not in tools and executables_by_tool.get('tsan'):
                    log_info("ğŸ”§ è‡ªåŠ¨å¯ç”¨ ThreadSanitizer (TSan)")
                    tools.append('tsan')

            # ===== æ­¥éª¤4: å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å·¥å…· =====
            all_results: List[Dict[str, Any]] = []
            all_issues: List[Dict[str, Any]] = []

            tasks = []
            log_info(f"ğŸ“‹ è®¡åˆ’æ‰§è¡Œçš„å·¥å…·: {', '.join(tools)}")

            for tool in tools:
                tool_execs = executables_by_tool.get(tool, [])
                
                if not tool_execs:
                    log_warning(f"   âš ï¸ å·¥å…· {tool} æ²¡æœ‰å¯¹åº”çš„å¯æ‰§è¡Œæ–‡ä»¶,è·³è¿‡")
                    continue
                
                log_info(f"   ğŸ”§ å·¥å…· {tool} å°†åˆ†æ {len(tool_execs)} ä¸ªå¯æ‰§è¡Œæ–‡ä»¶")
                
                for exe in tool_execs:
                    # äº’æ–¥æ£€æŸ¥
                    if tool == 'tsan' and self._is_asan_binary(exe):
                        log_warning(f"   âš ï¸ è·³è¿‡ ASan äºŒè¿›åˆ¶: {os.path.basename(exe)}")
                        continue
                    if tool == 'asan' and self._is_tsan_binary(exe):
                        log_warning(f"   âš ï¸ è·³è¿‡ TSan äºŒè¿›åˆ¶: {os.path.basename(exe)}")
                        continue
                    
                    # åˆ›å»ºä»»åŠ¡
                    if tool == 'valgrind_memcheck':
                        tasks.append(self._run_with_metadata(
                            self.valgrind.run_memcheck(exe, executable_args, timeout, output_dir),
                            tool, exe
                        ))
                    elif tool == 'asan':
                        tasks.append(self._run_with_metadata(
                            self.sanitizer.run_asan(exe, executable_args, timeout, output_dir),
                            tool, exe
                        ))
                    elif tool == 'tsan':
                        tasks.append(self._run_with_metadata(
                            self.sanitizer.run_tsan(exe, executable_args, timeout),
                            tool, exe
                        ))
                    elif tool == 'ubsan':
                        tasks.append(self._run_with_metadata(
                            self.sanitizer.run_ubsan(exe, executable_args, timeout),
                            tool, exe
                        ))

            log_info(f"ğŸš€ å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {len(tasks)} ä¸ªåˆ†æä»»åŠ¡...")

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            if tasks:
                results = await asyncio.gather(*tasks, return_exceptions=True)

                log_info("=" * 60)
                for i, result in enumerate(results):
                    if isinstance(result, Exception):
                        log_error(f"âŒ ä»»åŠ¡ #{i+1} æ‰§è¡Œå¼‚å¸¸: {result}")
                        continue

                    tool_name = result.get('tool', 'unknown')
                    exe_name = os.path.basename(result.get('executable', 'unknown'))
                    
                    if result.get('success'):
                        issue_count = len(result.get('issues', []))
                        if issue_count > 0:
                            log_info(f"âœ… {tool_name} [{exe_name}]: å‘ç° {issue_count} ä¸ªé—®é¢˜")
                    else:
                        error_msg = result.get('error', '')
                        if 'å¯æ‰§è¡Œæ–‡ä»¶ä¸å­˜åœ¨' not in error_msg:
                            log_error(f"âŒ {tool_name} [{exe_name}]: {error_msg}")

                    all_results.append(result)
                    
                    # æ ‡è®°æ¥æº
                    if result.get('success') and 'issues' in result:
                        for issue in result['issues']:
                            issue['source_executable'] = result.get('executable')
                            issue['source_tool'] = issue.get('tool', tool_name)
                            all_issues.append(issue)
                
                log_info("=" * 60)

            # ===== ğŸ”¥ æ­¥éª¤5: æ™ºèƒ½å»é‡ =====
            log_info("ğŸ§¹ å¼€å§‹å»é‡...")
            original_count = len(all_issues)
            deduplicated_issues = self._deduplicate_issues(all_issues)
            removed_count = original_count - len(deduplicated_issues)
            
            if removed_count > 0:
                log_info(f"âœ… å»é‡å®Œæˆ: ç§»é™¤ {removed_count} ä¸ªé‡å¤é—®é¢˜ ({original_count} -> {len(deduplicated_issues)})")
            else:
                log_info(f"âœ… æ— é‡å¤é—®é¢˜")

            # ğŸ†•ğŸ†•ğŸ†• ===== æ­¥éª¤6: AIæ™ºèƒ½åå¤„ç† =====
            enable_ai = config.get('enable_ai_postprocess', True)
            if enable_ai and deduplicated_issues:
                log_info("=" * 60)
                log_info("ğŸ¤– æ­¥éª¤6/6: AIæ™ºèƒ½åå¤„ç†(å»é‡+åˆ†æ+ä¿®å¤å»ºè®®)")
                log_info("=" * 60)
                
                try:
                    # æ„é€ ä¸´æ—¶ç»“æœç”¨äºAIåˆ†æ
                    temp_results = {
                        'issues': deduplicated_issues,
                        'summary': {
                            'total_issues': len(deduplicated_issues),
                            'analysis_tools': tools
                        }
                    }
                    
                    # è°ƒç”¨AIåå¤„ç†å™¨
                    ai_processor = get_ai_postprocessor()
                    ai_processed = await ai_processor.process_detection_results(
                        raw_results=temp_results,
                        project_path=project_path
                    )
                    
                    # æ›´æ–°issues(ä½¿ç”¨AIå¤„ç†åçš„)
                    deduplicated_issues = ai_processed.get('issues', deduplicated_issues)
                    
                    # æ·»åŠ AIåˆ†æç»“æœ
                    ai_classification = ai_processed.get('ai_classification', {})
                    repair_suggestions = ai_processed.get('repair_suggestions', [])
                    
                    log_info(f"âœ… AIå¤„ç†å®Œæˆ: {len(deduplicated_issues)} ä¸ªæœ€ç»ˆé—®é¢˜")
                    log_info(f"   - çœŸå®æ¼æ´: {len(ai_classification.get('real_vulnerabilities', []))}")
                    log_info(f"   - ä¿®å¤å»ºè®®: {len(repair_suggestions)}")
                    
                except Exception as e:
                    log_error(f"AIåå¤„ç†å¤±è´¥(å·²é™çº§): {e}")
                    # é™çº§:ç»§ç»­ä½¿ç”¨å»é‡åçš„ç»“æœ
                    ai_classification = {}
                    repair_suggestions = []
            else:
                log_info("â­ï¸  è·³è¿‡AIåå¤„ç†")
                ai_classification = {}
                repair_suggestions = []

            if not deduplicated_issues:
                log_warning("âš ï¸  åŠ¨æ€åˆ†ææœªå‘ç°ä»»ä½•é—®é¢˜ï¼ˆå¯èƒ½æ‰€æœ‰æ–‡ä»¶ç¼–è¯‘å¤±è´¥ï¼‰")
                return {
                    'success': True,  # â† å…³é”®ï¼šå³ä½¿æ²¡é—®é¢˜ä¹Ÿè¿”å›æˆåŠŸ
                    'tools_executed': tools,
                    'total_issues': 0,
                    'issues': [],
                    'tool_results': all_results,
                    'summary': {
                        'tools_run': len(tools),
                        'tools_succeeded': 0,
                        'tools_failed': len(tools),
                        'total_issues': 0,
                        'compilation_failed': True,  # â† æ ‡è®°ç¼–è¯‘å¤±è´¥
                        'message': 'æ‰€æœ‰å¯æ‰§è¡Œæ–‡ä»¶ç¼–è¯‘å¤±è´¥æˆ–æœªç”Ÿæˆé—®é¢˜'
                    },
                    'output_dir': output_dir,
                    'ai_classification': {},
                    'repair_suggestions': []
                }
                
            # ç»Ÿè®¡ç»“æœ
            summary = self._generate_summary(all_results, deduplicated_issues)
            
            # ğŸ†• æ·»åŠ AIåˆ†æç»Ÿè®¡
            summary['ai_processed'] = enable_ai and bool(deduplicated_issues)
            summary['repairs_generated'] = len(repair_suggestions)
            
            log_info(f"åŠ¨æ€åˆ†æå®Œæˆ,å…±å‘ç° {len(deduplicated_issues)} ä¸ªç‹¬ç«‹é—®é¢˜")

            return {
                'success': True,
                'tools_executed': tools,
                'total_issues': len(deduplicated_issues),
                'issues': deduplicated_issues,
                'tool_results': all_results,
                'summary': summary,
                'output_dir': output_dir,
                # ğŸ†• æ·»åŠ AIåˆ†æç»“æœ
                'ai_classification': ai_classification,
                'repair_suggestions': repair_suggestions
            }

        except Exception as e:
            log_error(f"åŠ¨æ€åˆ†ææ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            log_error(traceback.format_exc())
            return {
                'success': False,
                'error': str(e)
            }


    # ===== ğŸ”¥ æ–°å¢: æ™ºèƒ½å»é‡æ–¹æ³• =====

    def _extract_user_location(self, issue: Dict[str, Any]) -> Tuple[Optional[str], int]:
        """
        ç»ˆæä½ç½®æå–ï¼šä¼˜å…ˆ stack_trace â†’ location â†’ file
        è¿”å› (basename, line) ï¼Œline=0 è¡¨ç¤ºæœªçŸ¥
        """
        # ===== ä¼˜å…ˆçº§1: stack_traceï¼ˆæœ€å¯é ï¼Œæ‰€æœ‰å·¥å…·éƒ½æœ‰ï¼‰=====
        stack = issue.get('stack_trace', [])
        for frame in stack:
            frame_file = frame.get('file', '').strip()
            if not frame_file:
                continue
            # ç”¨æˆ·ä»£ç åˆ¤æ–­ï¼ˆä¸¥æ ¼è¿‡æ»¤ç³»ç»Ÿå¸§ï¼‰
            if frame_file.endswith(('.cpp', '.c', '.cc', '.cxx', '.h', '.hpp')):
                if any(bad in frame_file for bad in [
                    '/usr/', '/lib/', 'sanitizer_', 'tsan_', 'asan_', 'interceptors',
                    'string_fortified', 'libc_start', 'sysdeps'
                ]):
                    continue
                basename = os.path.basename(frame_file)
                line = frame.get('line', 0)
                if line > 0:
                    log_info(f"   ğŸ¯ stackæå–: {basename}:{line}")
                    return basename, line
        
        # ===== ä¼˜å…ˆçº§2: location å­—æ®µï¼ˆæ­£åˆ™è§£æï¼Œè¶…é²æ£’ï¼‰=====
        location = issue.get('location', '').strip()
        if location:
            # åŒ¹é…æœ€åé¢çš„ :æ•°å­—ï¼ˆæ”¯æŒ file.cpp:123 æˆ– file.cpp:123:1ï¼‰
            match = re.search(r':(\d+)(?::\d+)?\s*$', location)
            if match:
                line_num = int(match.group(1))
                # å–è·¯å¾„æœ€åä¸€éƒ¨åˆ†ä½œä¸ºbasename
                file_part = location.rsplit(':', 1)[0].strip()
                basename = os.path.basename(file_part)
                if basename.endswith(('.cpp', '.c', '.cc', '.cxx', '.h', '.hpp')):
                    log_info(f"   ğŸ¯ locationæå–: {basename}:{line_num}")
                    return basename, line_num
        
        # ===== ä¼˜å…ˆçº§3: é¡¶å±‚ file + line =====
        file_field = issue.get('file', '').strip()
        if file_field:
            line = issue.get('line', 0)
            if isinstance(line, (int, float)) and line > 0:
                basename = os.path.basename(file_field)
                if basename.endswith(('.cpp', '.c', '.cc', '.cxx', '.h', '.hpp')):
                    log_info(f"   ğŸ¯ fileå­—æ®µæå–: {basename}:{line}")
                    return basename, line
        
        log_warning(f"   âš ï¸ å®Œå…¨å¤±è´¥: {issue.get('type')} @ {location or 'unknown'}")
        return None, 0


    def _deduplicate_issues(self, issues: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ™ºèƒ½å»é‡ç»ˆæç‰ˆ"""
        seen: Dict[str, Dict[str, Any]] = {}
        data_race_count: Dict[str, int] = {}  # data-race ç‰¹æ®Šï¼šåŒä½ç½®æœ€å¤šä¿ç•™2ä¸ª
        
        for issue in issues:
            user_file, user_line = self._extract_user_location(issue)
            if not user_file:
                continue  # å½»åº•ç³»ç»Ÿå¸§ï¼Œä¸¢å¼ƒ
            
            issue_type = self._normalize_issue_type(issue.get('type', 'unknown'))
            
            # ===== ç”Ÿæˆkey =====
            if user_line > 0:
                key = f"{user_file}:{user_line}:{issue_type}"
            else:
                key = f"{user_file}::{issue_type}"
            
            # ===== data-race ç‰¹æ®Šå®½å®¹ =====
            if issue_type == 'data_race':
                if key not in data_race_count:
                    data_race_count[key] = 0
                if data_race_count[key] >= 2:
                    log_info(f"   â­ï¸ data-race è¶…é™è·³è¿‡: {key}")
                    continue
                data_race_count[key] += 1
            
            # ===== å»é‡æ ¸å¿ƒ =====
            new_score = self._calculate_issue_score(issue)
            if key not in seen:
                seen[key] = issue
                log_info(f"   âœ… æ–°é—®é¢˜: {key} (å¾—åˆ† {new_score})")
            else:
                old_score = self._calculate_issue_score(seen[key])
                if new_score > old_score:
                    log_info(f"   ğŸ”„ æ›´æ–°: {key} (å¾—åˆ† {new_score} > {old_score})")
                    seen[key] = issue
                else:
                    log_info(f"   â­ï¸ è·³è¿‡é‡å¤: {key} (å¾—åˆ† {new_score} <= {old_score})")
                
                # å¯é€‰ï¼šåˆå¹¶ detected_in åˆ—è¡¨
                if 'detected_in' not in seen[key]:
                    seen[key]['detected_in'] = []
                seen[key]['detected_in'].append(issue.get('source_executable', 'unknown'))
        
        log_info(f"ğŸ¯ å»é‡å®Œæˆ: {len(issues)} â†’ {len(seen)} ä¸ªç‹¬ç«‹é—®é¢˜")
        return list(seen.values())

    def _normalize_issue_type(self, raw_type: str) -> str:
        """è§„èŒƒåŒ–é—®é¢˜ç±»å‹åç§°"""
        if not raw_type:
            return 'unknown'
        
        type_map = {
            'heap-use-after-free': 'use_after_free',
            'heap-buffer-overflow': 'heap_overflow',
            'stack-buffer-overflow': 'stack_overflow',
            'data race': 'data_race',
            'data-race': 'data_race',
            'memory leak': 'memory_leak',
            'double-free': 'double_free',
        }
        
        normalized = raw_type.lower().replace(' ', '_')
        return type_map.get(normalized, normalized)

    def _calculate_issue_score(self, issue: Dict[str, Any]) -> int:
        """è®¡ç®—é—®é¢˜çš„ä¿¡æ¯å®Œæ•´åº¦å¾—åˆ†ï¼ˆç”¨äºå»é‡æ—¶é€‰æ‹©æ›´å®Œæ•´çš„è®°å½•ï¼‰"""
        score = 0
        
        # æœ‰å®Œæ•´å †æ ˆ +10
        if issue.get('stack_trace') and len(issue.get('stack_trace', [])) > 0:
            score += 10
        
        # æœ‰è¯¦ç»†æè¿° +5
        if issue.get('message') and len(issue.get('message', '')) > 20:
            score += 5
        
        # æœ‰æºç ä¸Šä¸‹æ–‡ +5
        if issue.get('source_code'):
            score += 5
        
        # æœ‰å»ºè®® +3
        if issue.get('suggestion'):
            score += 3
        
        return score

    def _issue_fingerprint(self, issue: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆé—®é¢˜æŒ‡çº¹(ç”¨äºç²¾ç¡®å»é‡)
        åŒ…æ‹¬: ç±»å‹+æ–‡ä»¶+è¡Œå·+æ¶ˆæ¯æ‘˜è¦
        """
        components = [
            issue.get('type', ''),
            issue.get('file', ''),
            str(issue.get('line', 0)),
            issue.get('message', '')[:100]  # åªå–å‰100å­—ç¬¦
        ]
        
        fingerprint_str = '|'.join(components)
        return hashlib.md5(fingerprint_str.encode()).hexdigest()

    # ===== å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜ =====
    
    def _discover_executables(self, project_path: str) -> List[str]:
        """æ‰«æç›®å½•,æŸ¥æ‰¾æ‰€æœ‰å¯æ‰§è¡Œæ–‡ä»¶"""
        executables = []
        
        try:
            for fname in os.listdir(project_path):
                fpath = os.path.join(project_path, fname)
                
                if not os.path.isfile(fpath):
                    continue
                if not os.access(fpath, os.X_OK):
                    continue
                
                # æ’é™¤è„šæœ¬å’Œåº“æ–‡ä»¶
                if fname.endswith(('.so', '.a', '.dylib', '.py', '.sh', '.o', '.txt', '.md')):
                    continue
                
                if fname.startswith('.'):
                    continue
                
                executables.append(os.path.abspath(fpath))
                
        except Exception as e:
            log_error(f"æ‰«æå¯æ‰§è¡Œæ–‡ä»¶å¤±è´¥: {e}")
        
        return executables

    def _group_executables_by_suffix(self, executables: List[str]) -> Dict[str, List[str]]:
        """æŒ‰åç¼€åˆ†ç»„å¯æ‰§è¡Œæ–‡ä»¶"""
        groups = {
            'valgrind_memcheck': [],
            'asan': [],
            'tsan': [],
            'ubsan': []
        }
        
        fallback_candidates = []
        
        for exe in executables:
            name = os.path.basename(exe)
            
            if name.endswith('_vg') or '_vg_' in name or 'valgrind' in name:
                groups['valgrind_memcheck'].append(exe)
            elif name.endswith('_asan') or '_asan_' in name:
                groups['asan'].append(exe)
            elif name.endswith('_tsan') or '_tsan_' in name:
                groups['tsan'].append(exe)
            elif name.endswith('_ubsan') or '_ubsan_' in name:
                groups['ubsan'].append(exe)
            else:
                fallback_candidates.append(exe)
        
        # å€™é€‰æ–‡ä»¶åˆ†é…
        for tool in ['valgrind_memcheck', 'asan']:
            if not groups[tool] and fallback_candidates:
                candidate = fallback_candidates[0]
                if tool == 'asan' and not self._is_tsan_binary(candidate):
                    groups[tool].append(candidate)
                elif tool == 'valgrind_memcheck' and not self._is_asan_binary(candidate):
                    groups[tool].append(candidate)
        
        return groups

    async def _run_with_metadata(
        self,
        task_coro,
        tool_name: str,
        executable_path: str
    ) -> Dict[str, Any]:
        """åŒ…è£…ä»»åŠ¡,æ·»åŠ å…ƒæ•°æ®"""
        try:
            result = await task_coro
            result['tool'] = tool_name
            result['executable'] = executable_path
            return result
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'tool': tool_name,
                'executable': executable_path
            }

    def _generate_summary(
        self,
        tool_results: List[Dict[str, Any]],
        all_issues: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ç”ŸæˆåŠ¨æ€åˆ†ææ‘˜è¦"""
        summary: Dict[str, Any] = {
            'tools_run': len(tool_results),
            'tools_succeeded': sum(1 for r in tool_results if r.get('success')),
            'tools_failed': sum(1 for r in tool_results if not r.get('success')),
            'total_issues': len(all_issues),
            'issues_by_severity': {},
            'issues_by_category': {},
            'issues_by_tool': {}
        }

        for issue in all_issues:
            severity = issue.get('severity', 'unknown')
            summary['issues_by_severity'][severity] = \
                summary['issues_by_severity'].get(severity, 0) + 1

        for issue in all_issues:
            category = issue.get('category', 'unknown')
            summary['issues_by_category'][category] = \
                summary['issues_by_category'].get(category, 0) + 1

        for issue in all_issues:
            tool = issue.get('source_tool', 'unknown')
            summary['issues_by_tool'][tool] = \
                summary['issues_by_tool'].get(tool, 0) + 1

        return summary

    def _detect_threading(self, project_path: str) -> bool:
        """æ£€æµ‹é¡¹ç›®æ˜¯å¦ä½¿ç”¨å¤šçº¿ç¨‹"""
        threading_keywords = [
            '#include <pthread.h>',
            'pthread_create',
            '#include <thread>',
            'std::thread',
            '#pragma omp'
        ]

        try:
            for root, dirs, files in os.walk(project_path):
                dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['build']]

                for file in files:
                    if file.endswith(('.cpp', '.cc', '.c', '.h', '.hpp')):
                        file_path = os.path.join(root, file)
                        try:
                            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                content = f.read()
                                for keyword in threading_keywords:
                                    if keyword in content:
                                        return True
                        except:
                            continue
            return False
        except:
            return False

    def _is_asan_binary(self, exe: str) -> bool:
        """æ£€æµ‹äºŒè¿›åˆ¶æ˜¯å¦åŒ…å« ASan"""
        try:
            out = subprocess.run(["ldd", exe], capture_output=True, text=True, timeout=5)
            if out.returncode == 0 and "libasan" in out.stdout:
                return True
        except:
            pass
        try:
            with open(exe, "rb") as f:
                blob = f.read(200000)
            return b"libasan" in blob
        except:
            return False

    def _is_tsan_binary(self, exe: str) -> bool:
        """æ£€æµ‹äºŒè¿›åˆ¶æ˜¯å¦åŒ…å« TSan"""
        try:
            out = subprocess.run(["ldd", exe], capture_output=True, text=True, timeout=5)
            if out.returncode == 0 and "libtsan" in out.stdout:
                return True
        except:
            pass
        try:
            with open(exe, "rb") as f:
                blob = f.read(200000)
            return b"libtsan" in blob
        except:
            return False

    # å…¼å®¹æ—§æ¥å£
    async def find_test_executables(self, project_path: str) -> List[str]:
        """æŸ¥æ‰¾æµ‹è¯•å¯æ‰§è¡Œæ–‡ä»¶"""
        return self._discover_executables(project_path)

    async def run_single_tool(
        self,
        tool_name: str,
        executable_path: str,
        args: List[str] = None,
        timeout: int = None,
        output_dir: str = None
    ) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªå·¥å…·"""
        timeout = timeout or self.default_timeout
        output_dir = output_dir or '/tmp'

        tool_mapping = {
            'valgrind_memcheck': self.valgrind.run_memcheck,
            'asan': self.sanitizer.run_asan,
            'ubsan': self.sanitizer.run_ubsan,
            'tsan': self.sanitizer.run_tsan
        }

        tool_func = tool_mapping.get(tool_name)
        if not tool_func:
            return {'success': False, 'error': f'æœªçŸ¥çš„å·¥å…·: {tool_name}'}

        try:
            if tool_name.startswith('valgrind') or tool_name == 'asan':
                result = await tool_func(executable_path, args, timeout, output_dir)
            else:
                result = await tool_func(executable_path, args, timeout)
            return result
        except Exception as e:
            return {'success': False, 'error': str(e)}

from typing import Dict, Any
import json
from pathlib import Path
from jinja2 import Template
import logging

logger = logging.getLogger(__name__)


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨ - ç”Ÿæˆå¤šæ ¼å¼æŠ¥å‘Š"""

    def __init__(self, template_dir: str = "configs/report_templates"):
        self.template_dir = Path(template_dir)

    def generate_html_report(
        self, analysis_result: Dict[str, Any], metrics: Dict[str, Any], output_path: str
    ) -> str:
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        template_path = self.template_dir / "executive_summary.html"

        # ä½¿ç”¨Jinja2æ¨¡æ¿ï¼ˆå¦‚æœæ²¡æœ‰æ¨¡æ¿æ–‡ä»¶ï¼Œä½¿ç”¨å†…è”æ¨¡æ¿ï¼‰
        html_content = self._render_html_template(analysis_result, metrics)

        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        output_file.write_text(html_content, encoding="utf-8")

        logger.info(f"HTML report generated: {output_path}")
        return str(output_file)

    def generate_markdown_report(
        self, analysis_result: Dict[str, Any], metrics: Dict[str, Any], output_path: str
    ) -> str:
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        md_content = self._build_markdown_content(analysis_result, metrics)

        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        output_file.write_text(md_content, encoding="utf-8")

        logger.info(f"Markdown report generated: {output_path}")
        return str(output_file)

    def _render_html_template(self, analysis: Dict, metrics: Dict) -> str:
        """æ¸²æŸ“HTMLæ¨¡æ¿"""
        # ç®€åŒ–ç‰ˆå†…è”æ¨¡æ¿
        html_template = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Bug Detector - åˆ†ææŠ¥å‘Š</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            border-radius: 10px;
            margin-bottom: 30px;
        }
        .score-card {
            display: inline-block;
            background: white;
            padding: 20px;
            border-radius: 10px;
            font-size: 48px;
            font-weight: bold;
            color: {{ score_color }};
        }
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        .metric-card {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .metric-card h3 {
            margin-top: 0;
            color: #667eea;
        }
        .issue-list {
            background: white;
            padding: 20px;
            border-radius: 8px;
            margin-top: 20px;
        }
        .issue-item {
            border-left: 4px solid #f56565;
            padding: 15px;
            margin: 10px 0;
            background: #fff5f5;
        }
        .issue-item.medium {
            border-left-color: #ed8936;
            background: #fffaf0;
        }
        .severity-badge {
            display: inline-block;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 12px;
            font-weight: bold;
        }
        .severity-high {
            background: #fed7d7;
            color: #c53030;
        }
        .severity-medium {
            background: #feebc8;
            color: #c05621;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ” AI Bug Detector åˆ†ææŠ¥å‘Š</h1>
        <div class="score-card" style="color: {{ score_color }};">
            {{ quality_score }} / 100
        </div>
        <p>ç­‰çº§: {{ quality_grade }}</p>
        <p>ç”Ÿæˆæ—¶é—´: {{ timestamp }}</p>
    </div>

    <div class="metrics-grid">
        <div class="metric-card">
            <h3>ğŸ“Š æ£€æµ‹æ¦‚è§ˆ</h3>
            <p><strong>æ€»é—®é¢˜æ•°:</strong> {{ total_issues }}</p>
            <p><strong>åˆ†ææ–‡ä»¶:</strong> {{ files_analyzed }}</p>
            <p><strong>é«˜å±é—®é¢˜:</strong> <span class="severity-badge severity-high">{{ high_count }}</span></p>
            <p><strong>ä¸­å±é—®é¢˜:</strong> <span class="severity-badge severity-medium">{{ medium_count }}</span></p>
        </div>

        <div class="metric-card">
            <h3>ğŸ› ï¸ ä¿®å¤å»ºè®®</h3>
            <p><strong>ç”Ÿæˆå»ºè®®:</strong> {{ repairs_generated }}</p>
            <p><strong>å¯è‡ªåŠ¨åº”ç”¨:</strong> {{ auto_applicable }}</p>
            <p><strong>è¦†ç›–ç‡:</strong> {{ repair_coverage }}%</p>
        </div>

        <div class="metric-card">
            <h3>âš¡ æ€§èƒ½ç»Ÿè®¡</h3>
            <p><strong>æ€»è€—æ—¶:</strong> {{ total_time }}s</p>
            <p><strong>é™æ€åˆ†æ:</strong> {{ static_time }}s ({{ static_percentage }}%)</p>
            <p><strong>åŠ¨æ€éªŒè¯:</strong> {{ dynamic_time }}s ({{ dynamic_percentage }}%)</p>
        </div>

        <div class="metric-card">
            <h3>âœ… éªŒè¯ç»“æœ</h3>
            <p><strong>éªŒè¯å‰:</strong> {{ validated_before }}</p>
            <p><strong>éªŒè¯å:</strong> {{ validated_after }}</p>
            <p><strong>è¯¯æŠ¥ç‡:</strong> {{ false_positive_rate }}%</p>
        </div>
    </div>

    <div class="issue-list">
        <h2>ğŸš¨ Top 10 å…³é”®é—®é¢˜</h2>
        {% for issue in top_issues %}
        <div class="issue-item {{ issue.severity }}">
            <p><strong>{{ issue.file }}:{{ issue.line }}</strong></p>
            <p>{{ issue.message }}</p>
            <p><span class="severity-badge severity-{{ issue.severity }}">{{ issue.severity }}</span> | å·¥å…·: {{ issue.tool }}</p>
        </div>
        {% endfor %}
    </div>
</body>
</html>
        """

        # å‡†å¤‡æ¨¡æ¿å˜é‡
        quality_score = metrics["quality_score"]["score"]
        score_color = (
            "#48bb78"
            if quality_score >= 80
            else ("#ed8936" if quality_score >= 60 else "#f56565")
        )

        top_issues = sorted(
            analysis["issues"],
            key=lambda x: (x.get("severity") == "high", x.get("priority_score", 0)),
            reverse=True,
        )[:10]

        template = Template(html_template)
        return template.render(
            quality_score=quality_score,
            quality_grade=metrics["quality_score"]["grade"],
            score_color=score_color,
            timestamp=metrics["timestamp"],
            total_issues=analysis["summary"]["total_issues"],
            files_analyzed=analysis["summary"]["files_analyzed"],
            high_count=analysis["summary"]["severity_distribution"].get("high", 0),
            medium_count=analysis["summary"]["severity_distribution"].get("medium", 0),
            repairs_generated=metrics["repair"]["suggestions_generated"],
            auto_applicable=metrics["repair"]["auto_applicable"],
            repair_coverage=round(metrics["repair"]["coverage_rate"] * 100, 1),
            total_time=round(metrics["performance"]["total_time"], 2),
            static_time=round(metrics["performance"]["static_time"], 2),
            dynamic_time=round(metrics["performance"]["dynamic_time"], 2),
            static_percentage=metrics["performance"]["breakdown_percentage"][
                "static_analysis"
            ],
            dynamic_percentage=metrics["performance"]["breakdown_percentage"][
                "dynamic_analysis"
            ],
            validated_before=analysis["summary"]["validated_before"],
            validated_after=analysis["summary"]["validated_after"],
            false_positive_rate=round(
                metrics["detection"]["false_positive_estimation"] * 100, 1
            ),
            top_issues=top_issues,
        )

    def _build_markdown_content(self, analysis: Dict, metrics: Dict) -> str:
        """æ„å»ºMarkdownå†…å®¹"""
        quality_score = metrics["quality_score"]

        md_content = f"""# ğŸ” AI Bug Detector åˆ†ææŠ¥å‘Š

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

**ä»£ç è´¨é‡è¯„åˆ†**: {quality_score['score']}/100 ({quality_score['grade']}ç­‰çº§)

**ç”Ÿæˆæ—¶é—´**: {metrics['timestamp']}

---

## ğŸ¯ æ£€æµ‹æ¦‚è§ˆ

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»é—®é¢˜æ•° | {analysis['summary']['total_issues']} |
| åˆ†ææ–‡ä»¶æ•° | {analysis['summary']['files_analyzed']} |
| é«˜å±é—®é¢˜ | {analysis['summary']['severity_distribution'].get('high', 0)} |
| ä¸­å±é—®é¢˜ | {analysis['summary']['severity_distribution'].get('medium', 0)} |
| è¯¯æŠ¥ç‡ä¼°è®¡ | {round(metrics['detection']['false_positive_estimation'] * 100, 1)}% |

---

## ğŸ› ï¸ ä¿®å¤å»ºè®®

- **ç”Ÿæˆå»ºè®®æ•°**: {metrics['repair']['suggestions_generated']}
- **å¯è‡ªåŠ¨åº”ç”¨**: {metrics['repair']['auto_applicable']}
- **è¦†ç›–ç‡**: {round(metrics['repair']['coverage_rate'] * 100, 1)}%

---

## âš¡ æ€§èƒ½ç»Ÿè®¡

- **æ€»è€—æ—¶**: {round(metrics['performance']['total_time'], 2)}ç§’
- **é™æ€åˆ†æ**: {round(metrics['performance']['static_time'], 2)}ç§’ ({metrics['performance']['breakdown_percentage']['static_analysis']}%)
- **åŠ¨æ€éªŒè¯**: {round(metrics['performance']['dynamic_time'], 2)}ç§’ ({metrics['performance']['breakdown_percentage']['dynamic_analysis']}%)

---

## ğŸš¨ Top 10 å…³é”®é—®é¢˜

"""

        top_issues = sorted(
            analysis["issues"],
            key=lambda x: (x.get("severity") == "high", x.get("priority_score", 0)),
            reverse=True,
        )[:10]

        for i, issue in enumerate(top_issues, 1):
            md_content += f"""
### {i}. {issue['file']}:{issue['line']}

- **ä¸¥é‡åº¦**: {issue['severity']}
- **ç±»å‹**: {issue['category']}
- **å·¥å…·**: {issue['tool']}
- **æè¿°**: {issue['message']}

"""

        return md_content
